{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "EPOCHS = 50\n",
    "learning_rate_initial = 0.1\n",
    "num_class = 10\n",
    "schedule_step = 15\n",
    "gamma_val = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "train_transform = transforms.Compose([transforms.RandomRotation(5),\n",
    "                                      transforms.RandomHorizontalFlip(0.3),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean = [0.485, 0.456, 0.406],\n",
    "                                                           std = [0.229, 0.224, 0.225])\n",
    "                                     ])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean = [0.485, 0.456, 0.406],\n",
    "                                                          std = [0.229, 0.224, 0.225])\n",
    "                                    ])\n",
    "\n",
    "# Load data\n",
    "train_set = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform =  train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size, shuffle = True, num_workers = 4)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size = batch_size, shuffle = False, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = {\n",
    "    'vgg11': [64, 'maxpool', 128, 'maxpool', 256, 256, 'maxpool', 512, 512, 'maxpool', 512, 512, 'maxpool'],\n",
    "    'vgg13': [64, 64, 'maxpool', 128, 128, 'maxpool', 256, 256, 'maxpool', 512, 512, 'maxpool', 512, 512, 'maxpool'],\n",
    "    'vgg16': [64, 64, 'maxpool', 128, 128, 'maxpool', 256, 256, 256, 'maxpool', 512, 512, 512, 'maxpool', 512, 512, 512, 'maxpool'],\n",
    "    'vgg19': [64, 64, 'maxpool', 128, 128, 'maxpool', 256, 256, 256, 256, 'maxpool', 512, 512, 512, 512, 'maxpool', 512, 512, 512, 512, 'maxpool']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(VGG, self).__init__()\n",
    "        self.conv_layers = self.get_conv_layers(config)\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size = 1, stride = 1)\n",
    "        self.fc = self.get_fc_layers()\n",
    "        \n",
    "        # Parameter Initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode = 'fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "        \n",
    "    def get_conv_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for layer in cfg:\n",
    "            if layer == 'maxpool':\n",
    "                layers += [nn.MaxPool2d(kernel_size = 2, stride = 2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, layer, kernel_size = 3, padding = 1),\n",
    "                           nn.BatchNorm2d(layer),\n",
    "                           nn.ReLU(inplace = True)]\n",
    "                in_channels = layer\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def get_fc_layers(self):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(512, num_class)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and send to GPU. \n",
    "vgg16 = VGG(configuration['vgg16'])\n",
    "vgg16.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function, Optimizer, Learning Rate Scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(vgg16.parameters(), lr = learning_rate_initial, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = schedule_step, gamma = gamma_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# Train the data\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"Epoch: \", epoch + 1)\n",
    "    vgg16.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        outputs = vgg16(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    running_loss /= len(train_loader)\n",
    "    train_loss_list.append(running_loss)\n",
    "    print('[%d] loss: %.3f' % (epoch + 1, running_loss))\n",
    "    \n",
    "    vgg16.eval()\n",
    "    train_total = 0\n",
    "    train_correct = 0\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in train_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "    \n",
    "            outputs = vgg16(Variable(images))\n",
    "            i, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "    \n",
    "            outputs = vgg16(Variable(images))\n",
    "            i, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    train_acc_list.append(100 * train_correct / train_total)  \n",
    "    test_acc_list.append(100 * correct / total)\n",
    "    print('Training Accuracy of current epoch: %.3f %%' % (100 * train_correct / train_total))\n",
    "    print('Testing Accuracy of current epoch: %.3f %%' % (100 * correct / total))\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_list)\n",
    "plt.title('Training Loss Plot of Each Epoch')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_acc_list)\n",
    "plt.title('Training Accuracy Plot of Each Epoch')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(test_acc_list)\n",
    "plt.title('Test Accuracy Plot of Each Epoch')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
